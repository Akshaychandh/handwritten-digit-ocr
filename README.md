# ğŸ”¢ Handwritten Digit OCR

A deep learning pipeline to extract handwritten number sequences from images.  
Trained on **MNIST** using a custom **CNN in PyTorch** â€” no external OCR APIs used.

---

## ğŸ“ Repo Structure

```
handwritten-digit-ocr/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ocr_digits.py        â† Main OCR script
â”œâ”€â”€ output/
â”‚   â””â”€â”€ digit_cnn.pth        â† Trained model weights (after training)
â”œâ”€â”€ report/
â”‚   â””â”€â”€ OCR_Report.docx      â† Full technical report
â”œâ”€â”€ Train_DigitOCR.ipynb     â† Google Colab training notebook
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Clone the repo
```bash
git clone https://github.com/YOUR_USERNAME/handwritten-digit-ocr.git
cd handwritten-digit-ocr
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Train on Google Colab *(recommended â€” free GPU)*
- Open `Train_DigitOCR.ipynb` in [Google Colab](https://colab.research.google.com/)
- Set **Runtime â†’ T4 GPU**
- Run all cells
- Download `digit_cnn.pth` â†’ place it in `output/`

### 4. Run OCR on your images
```bash
# Single image
python src/ocr_digits.py images/sample.jpg --model output/digit_cnn.pth

# Folder of images + debug visualisation
python src/ocr_digits.py images/ --model output/digit_cnn.pth --debug
```

---

## ğŸ§  Model Architecture

| Layer        | Config              | Output       |
|--------------|---------------------|--------------|
| Conv1        | 3Ã—3, 32 filters     | 32 Ã— 28 Ã— 28 |
| Conv2        | 3Ã—3, 64 filters     | 64 Ã— 28 Ã— 28 |
| MaxPool + Dropout | 2Ã—2, 25%      | 64 Ã— 14 Ã— 14 |
| Conv3        | 3Ã—3, 128 filters    | 128 Ã— 14 Ã— 14|
| MaxPool + Dropout | 2Ã—2, 25%      | 128 Ã— 7 Ã— 7  |
| FC1          | 6272 â†’ 256, Dropout | 256          |
| FC2 (Output) | 256 â†’ 10            | 10 classes   |

**Optimizer:** Adam | **LR:** 1e-3 â†’ StepLR | **Epochs:** 10  
**Test Accuracy on MNIST:** >99.2%

---

## ğŸ”„ Pipeline

```
Input Image
    â†“ Grayscale + Gaussian Blur
    â†“ Adaptive Thresholding (handles uneven lighting)
    â†“ Morphological Close (fill digit gaps)
    â†“ Contour Detection + Line Grouping
    â†“ 28Ã—28 Crop per digit
    â†“ CNN Inference
    â†“ JSON Output
```

---

## ğŸ“Š Output Format

Results are saved to `output/results.json`:
```json
[
  {
    "image": "receipt.jpg",
    "lines": [
      { "line": 1, "text": "7012233066", "digits": [
          { "digit": 7, "confidence": 0.99, "bbox": [10, 5, 12, 20] }
        ]
      }
    ],
    "full_text": "7012233066 01534 23.19"
  }
]
```

---

## ğŸ›  Tech Stack

| Tool | Purpose |
|------|---------|
| PyTorch | CNN training & inference |
| torchvision | MNIST dataset + transforms |
| OpenCV | Image preprocessing & segmentation |
| Pillow | Image loading |
| NumPy | Array operations |

---

## ğŸ“„ Report

See [`report/OCR_Report.docx`](report/OCR_Report.docx) for the full technical report covering architecture, results, challenges, and findings.

---

## ğŸ“ Assignment Constraints Met

- âœ… No external OCR APIs (no Google Vision, Tesseract API, AWS Textract)
- âœ… Open-source tools only
- âœ… Deep learning approach (CNN)
- âœ… MNIST dataset used for training
- âœ… Code + Report submitted
